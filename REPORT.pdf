### REPORT

#### 1. Introduction and System Design

This project focuses on building an interactive system for association rule mining using real or user-uploaded supermarket transactions. The application integrates data preprocessing, frequent-itemset mining (Apriori and Eclat), and a user-friendly Streamlit interface. Users can explore how different thresholds affect rule generation and view personalized product recommendations based on mined associations.

The system design follows a modular architecture:
	•	UI Layer (Streamlit): Handles all interactions, file uploads, visualizations, and user controls.
	•	Preprocessing Module: Cleans and normalizes transaction data for mining.
	•	Algorithms Layer: Contains Apriori and Eclat implementations from scratch.
	•	Main Application: Combines all components into a unified workflow.

This separation ensures clarity, maintainability, and easier expansion (e.g., adding new algorithms later).

⸻

#### 2. Data Preprocessing Approach

Before applying association rule mining, the raw CSV transaction data undergoes several cleaning steps to ensure quality and consistency:

Steps Performed
	1.	Column Selection:
If the CSV has multiple columns, the system automatically uses the last column as the items list.
	2.	String Normalization:
	•	Lowercasing
	•	Removing extra spaces
	•	Splitting items by commas or whitespace
	3.	Removing Empty Transactions:
Transactions with no valid items are discarded.
	4.	Duplicate Item Removal:
Repeated items within a single transaction are counted as one instance.
	5.	Single-Item Transaction Removal:
Since these offer no associations, they are removed from the dataset.
	6.	Invalid Product Filtering:
Using products.csv, items not recognized in the product list are removed.

Outcome

Cleaned transactions contain:
	•	Only valid products
	•	No duplicates
	•	At least two items
	•	Normalized, consistent formatting

This preprocessing step significantly impacts algorithm performance and rule quality.

⸻

#### 3. Algorithm Implementation Details

Both Apriori and Eclat were implemented manually in Python using basic data structures (sets, lists, dictionaries). Below are the explanations and pseudocode for each.

⸻

##### 3.1 Apriori Algorithm

Apriori uses a level-wise, breadth-first search approach. It generates candidate itemsets of size k from frequent itemsets of size k − 1, and prunes candidates whose subsets are infrequent.

Data Structure
	•	A dictionary storing frequent itemsets:
L[k] = {frozenset(itemset): support}

Pseudocode
```
function APRIORI(transactions, min_support):
    L1 = find frequent 1-itemsets
    L = {1: L1}
    k = 2

    while L[k-1] not empty:
        Ck = generate candidates from L[k-1]
        prune candidates with infrequent subsets
        count support for each candidate
        Lk = itemsets with support >= min_support
        L[k] = Lk
        k = k + 1

    return L
```
Rule Generation
Rules are created using:
```
confidence = support(A ∪ B) / support(A)
lift = confidence / support(B)
```
##### 3.2 Eclat Algorithm

Eclat uses a depth-first search strategy and relies on vertical data format, where each item is mapped to a set of transaction IDs (TID sets).

Data Structure
	•	Dictionary of TID sets:
item → set(transaction_ids)

Mining Approach
Frequent itemsets are discovered by intersecting TID sets recursively.

Pseudocode
```
function ECLAT(prefix, items_tidsets):
    for each (item, tidset) in items_tidsets:
        new_itemset = prefix ∪ item
        support = |tidset| / total_transactions

        if support >= min_support:
            output new_itemset
            new_items = intersect tidsets of remaining items
            ECLAT(new_itemset, new_items)
```

